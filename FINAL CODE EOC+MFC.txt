import cv2
import os
import numpy as np
import torch
import yaml
from ultralytics import YOLO
from typing import List, Dict
from scipy.spatial.distance import cdist

class CombatZoneObjectTracker:
    def __init__(self, model_path: str = 'best.pt', train_data: str = '/kaggle/input/plzzz-bro/data.yaml', epochs: int = 10):
        if not os.path.exists(model_path):
            print("Trained model not found. Starting training...")
            self._train_model(train_data, epochs)
        else:
            print(f"Loading trained model: {model_path}")
        
        # Initialize class names from data.yaml
        self.class_names = self._load_class_names(train_data)
        print(f"Loaded {len(self.class_names)} class names from dataset")
        
        self.detection_model = YOLO(model_path)
        print("YOLO model loaded successfully")
        
        # Tracking state
        self.kalman_filters = {}
        self.last_positions = {}
        self.last_bboxes = {}
        self.track_history = {}  # Store history of positions for each tracker
        self.class_history = {}  # Store history of class IDs for each tracker
        self.next_id = 0
        
        # Improved parameters
        self.disappeared_count = {}
        self.max_disappeared = 60  # Increased from 30 to 60 frames for more persistence
        self.distance_threshold = 150  # Increased from 100 to 150 for better matching
        
        # Additional parameters for better tracking
        self.iou_threshold = 0.3  # Threshold for IOU matching
        self.history_length = 20  # Number of frames to keep in history
        self.min_hits = 3  # Minimum detections before considering a track confirmed

    def _load_class_names(self, data_yaml_path: str) -> dict:
        """Load class names from YOLO data.yaml file"""
        try:
            with open(data_yaml_path, 'r') as f:
                data = yaml.safe_load(f)
                
            # YOLO data.yaml can have class names in different formats
            if 'names' in data:
                if isinstance(data['names'], dict):
                    return data['names']  # Already a dictionary
                elif isinstance(data['names'], list):
                    # Convert list to dictionary
                    return {i: name for i, name in enumerate(data['names'])}
            
            print("Warning: Could not find class names in data.yaml. Using generic class IDs.")
            return {}  # Return empty dict if no class names found
            
        except Exception as e:
            print(f"Error loading class names from {data_yaml_path}: {e}")
            # Fallback to generic class IDs
            return {}

    def _train_model(self, data_path: str, epochs: int):
        model = YOLO("yolov8m.pt")  # Start with YOLOv8 Medium
        model.train(data=data_path, epochs=epochs)
        trained_model_path = "runs/train/exp/weights/best.pt"
        if os.path.exists(trained_model_path):
            print(f"Training complete. Using {trained_model_path}")
            self.detection_model = YOLO(trained_model_path)
        else:
            print("Error: Training failed, model not found.")

    def _initialize_kalman_filter(self):
        kalman = cv2.KalmanFilter(8, 4)  # 8-state: [x, y, w, h, vx, vy, vw, vh], 4-measurement: [x, y, w, h]
        
        # Set measurement matrix to relate state to measurement
        kalman.measurementMatrix = np.array([
            [1, 0, 0, 0, 0, 0, 0, 0],
            [0, 1, 0, 0, 0, 0, 0, 0],
            [0, 0, 1, 0, 0, 0, 0, 0],
            [0, 0, 0, 1, 0, 0, 0, 0]
        ], np.float32)
        
        # Set transition matrix for constant velocity model (includes box dimensions)
        kalman.transitionMatrix = np.array([
            [1, 0, 0, 0, 1, 0, 0, 0],  # x = x + vx
            [0, 1, 0, 0, 0, 1, 0, 0],  # y = y + vy
            [0, 0, 1, 0, 0, 0, 1, 0],  # w = w + vw
            [0, 0, 0, 1, 0, 0, 0, 1],  # h = h + vh
            [0, 0, 0, 0, 1, 0, 0, 0],  # vx = vx
            [0, 0, 0, 0, 0, 1, 0, 0],  # vy = vy
            [0, 0, 0, 0, 0, 0, 1, 0],  # vw = vw
            [0, 0, 0, 0, 0, 0, 0, 1]   # vh = vh
        ], np.float32)
        
        # Tune process noise for different state components
        kalman.processNoiseCov = np.diag([
            0.01,  # x position
            0.01,  # y position
            0.01,  # width
            0.01,  # height
            0.1,   # x velocity - higher noise
            0.1,   # y velocity - higher noise
            0.01,  # width change
            0.01   # height change
        ]).astype(np.float32)
        
        # Tune measurement noise
        kalman.measurementNoiseCov = np.diag([
            0.1,  # x position measurement
            0.1,  # y position measurement
            0.5,  # width measurement - higher noise
            0.5   # height measurement - higher noise
        ]).astype(np.float32)
        
        return kalman

    def _calculate_iou(self, box1, box2):
        """Calculate IoU between two bounding boxes [x1, y1, x2, y2]"""
        # Extract coordinates
        x1_1, y1_1, x2_1, y2_1 = box1
        x1_2, y1_2, x2_2, y2_2 = box2
        
        # Calculate area of each box
        area1 = (x2_1 - x1_1) * (y2_1 - y1_1)
        area2 = (x2_2 - x1_2) * (y2_2 - y1_2)
        
        # Calculate coordinates of intersection
        x1_i = max(x1_1, x1_2)
        y1_i = max(y1_1, y1_2)
        x2_i = min(x2_1, x2_2)
        y2_i = min(y2_1, y2_2)
        
        # Calculate intersection area
        if x2_i <= x1_i or y2_i <= y1_i:
            return 0.0  # No intersection
        
        intersection_area = (x2_i - x1_i) * (y2_i - y1_i)
        
        # Calculate union area
        union_area = area1 + area2 - intersection_area
        
        # Calculate IoU
        return intersection_area / union_area if union_area > 0 else 0.0
    
    def get_class_name(self, class_id):
        """Convert numeric class ID to human-readable name"""
        return self.class_names.get(class_id, f"Class {class_id}")
    
    def detect_objects(self, frame: np.ndarray) -> List[Dict]:
        results = self.detection_model(frame, conf=0.4)  # Slightly higher confidence threshold
        detected_objects = []
        
        for result in results:
            for box in result.boxes:
                x1, y1, x2, y2 = map(int, box.xyxy[0])
                confidence = float(box.conf[0])
                class_id = int(box.cls[0])
                
                # Skip small detections as they're often false positives
                w, h = x2 - x1, y2 - y1
                if w < 20 or h < 20:
                    continue
                
                center_x = (x1 + x2) / 2
                center_y = (y1 + y2) / 2
                
                detected_objects.append({
                    'bbox': [x1, y1, x2, y2],
                    'width': w,
                    'height': h,
                    'confidence': confidence,
                    'center': (center_x, center_y),
                    'class_id': class_id
                })
        
        return detected_objects
    
    def _get_dominant_class(self, tracker_id):
        """Return the most common class ID for this tracker"""
        if tracker_id not in self.class_history or not self.class_history[tracker_id]:
            return None
        
        # Count occurrences of each class
        class_counts = {}
        for class_id in self.class_history[tracker_id]:
            if class_id not in class_counts:
                class_counts[class_id] = 0
            class_counts[class_id] += 1
        
        # Return the most common class
        return max(class_counts, key=class_counts.get)
    
    def track_objects(self, detected_objects: List[Dict]) -> List[Dict]:
        tracked_objects = []
        predicted_positions = {}  # Store predicted future positions
        
        # Mark all existing trackers as disappeared for this frame
        for tracker_id in list(self.last_positions.keys()):
            if tracker_id not in self.disappeared_count:
                self.disappeared_count[tracker_id] = 0
            self.disappeared_count[tracker_id] += 1
        
        # If no objects detected, update disappeared counters and return empty list
        if len(detected_objects) == 0:
            # Remove trackers that have been missing for too long
            for tracker_id in list(self.disappeared_count.keys()):
                if self.disappeared_count[tracker_id] > self.max_disappeared:
                    if tracker_id in self.kalman_filters:
                        del self.kalman_filters[tracker_id]
                    if tracker_id in self.last_positions:
                        del self.last_positions[tracker_id]
                    if tracker_id in self.last_bboxes:
                        del self.last_bboxes[tracker_id]
                    if tracker_id in self.track_history:
                        del self.track_history[tracker_id]
                    if tracker_id in self.class_history:
                        del self.class_history[tracker_id]
                    del self.disappeared_count[tracker_id]
            return []
        
        # If we have no existing trackers, initialize all as new
        if len(self.last_positions) == 0:
            for obj in detected_objects:
                center = obj['center']
                bbox = obj['bbox']
                width = obj['width']
                height = obj['height']
                class_id = obj['class_id']
                
                tracker_id = self.next_id
                self.next_id += 1
                
                # Initialize Kalman filter
                self.kalman_filters[tracker_id] = self._initialize_kalman_filter()
                kalman = self.kalman_filters[tracker_id]
                
                # Initialize state
                state = np.array([center[0], center[1], width, height, 0, 0, 0, 0], np.float32)
                kalman.statePost = state.reshape(8, 1)
                
                # Initialize history tracking
                self.last_positions[tracker_id] = center
                self.last_bboxes[tracker_id] = bbox
                self.track_history[tracker_id] = [center]
                self.class_history[tracker_id] = [class_id]
                self.disappeared_count[tracker_id] = 0
                
                tracked_objects.append({
                    **obj,
                    'tracker_id': tracker_id,
                    'dominant_class': class_id
                })
        else:
            # First prediction step for all existing Kalman filters
            predictions = {}
            for tracker_id, kalman in self.kalman_filters.items():
                prediction = kalman.predict()
                x, y, w, h = prediction[0:4]
                x, y, w, h = float(x), float(y), float(w), float(h)
                pred_bbox = [x - w/2, y - h/2, x + w/2, y + h/2]  # convert to [x1,y1,x2,y2]
                predictions[tracker_id] = {
                    'center': (x, y),
                    'bbox': pred_bbox,
                    'width': w,
                    'height': h
                }
                
                # Calculate future position (10 frames ahead)
                vx, vy = float(prediction[4]), float(prediction[5])  # Velocity components
                future_x = x + 10 * vx
                future_y = y + 10 * vy
                future_bbox = [future_x - w/2, future_y - h/2, future_x + w/2, future_y + h/2]
                predicted_positions[tracker_id] = future_bbox
            
            # Calculate IoU matrix between predictions and detections
            iou_matrix = np.zeros((len(self.last_positions), len(detected_objects)))
            for i, tracker_id in enumerate(self.last_positions.keys()):
                for j, obj in enumerate(detected_objects):
                    if tracker_id in predictions:
                        iou = self._calculate_iou(predictions[tracker_id]['bbox'], obj['bbox'])
                        iou_matrix[i, j] = iou
            
            # Calculate distance matrix for centers
            dist_matrix = np.zeros((len(self.last_positions), len(detected_objects)))
            tracker_ids = list(self.last_positions.keys())
            centers = [predictions[tid]['center'] for tid in tracker_ids]
            detection_centers = [obj['center'] for obj in detected_objects]
            
            if centers and detection_centers:
                dist_matrix = cdist(centers, detection_centers)
            
            # Combined matching using IoU and distance
            matched_indices = []
            
            # First, try matching with IoU
            for i, tracker_id in enumerate(tracker_ids):
                for j in range(len(detected_objects)):
                    if iou_matrix[i, j] > self.iou_threshold:
                        matched_indices.append((i, j))
                        break
            
            # For unmatched trackers and detections, try distance-based matching
            matched_trackers = {i for i, _ in matched_indices}
            matched_detections = {j for _, j in matched_indices}
            
            for i, tracker_id in enumerate(tracker_ids):
                if i in matched_trackers:
                    continue
                    
                # Get class history for this tracker
                dominant_class = self._get_dominant_class(tracker_id)
                
                for j in range(len(detected_objects)):
                    if j in matched_detections:
                        continue
                        
                    # Check if distance is within threshold
                    if dist_matrix[i, j] <= self.distance_threshold:
                        # Bonus: check if class matches dominant class (if available)
                        if dominant_class is not None and detected_objects[j]['class_id'] == dominant_class:
                            matched_indices.append((i, j))
                            matched_trackers.add(i)
                            matched_detections.add(j)
                            break
                
                # If still not matched by class, just use distance
                if i not in matched_trackers:
                    min_dist_idx = None
                    min_dist = float('inf')
                    for j in range(len(detected_objects)):
                        if j in matched_detections:
                            continue
                        if dist_matrix[i, j] < min_dist and dist_matrix[i, j] <= self.distance_threshold:
                            min_dist = dist_matrix[i, j]
                            min_dist_idx = j
                    
                    if min_dist_idx is not None:
                        matched_indices.append((i, min_dist_idx))
                        matched_trackers.add(i)
                        matched_detections.add(min_dist_idx)
            
            # Update matched trackers
            for i, j in matched_indices:
                tracker_id = tracker_ids[i]
                obj = detected_objects[j]
                
                # Update Kalman filter with new measurement
                kalman = self.kalman_filters[tracker_id]
                measurement = np.array([
                    obj['center'][0], 
                    obj['center'][1], 
                    obj['width'], 
                    obj['height']
                ], dtype=np.float32).reshape(4, 1)
                
                kalman.correct(measurement)
                
                # Update last known position and bbox
                self.last_positions[tracker_id] = obj['center']
                self.last_bboxes[tracker_id] = obj['bbox']
                
                # Update history
                self.track_history[tracker_id].append(obj['center'])
                if len(self.track_history[tracker_id]) > self.history_length:
                    self.track_history[tracker_id] = self.track_history[tracker_id][-self.history_length:]
                
                self.class_history[tracker_id].append(obj['class_id'])
                if len(self.class_history[tracker_id]) > self.history_length:
                    self.class_history[tracker_id] = self.class_history[tracker_id][-self.history_length:]
                
                # Reset disappeared counter
                self.disappeared_count[tracker_id] = 0
                
                # Add to tracked objects with dominant class
                dominant_class = self._get_dominant_class(tracker_id)
                
                # Add predicted future position if available
                obj_with_tracking = {
                    **obj,
                    'tracker_id': tracker_id,
                    'dominant_class': dominant_class
                }
                
                if tracker_id in predicted_positions:
                    obj_with_tracking['predicted_bbox'] = predicted_positions[tracker_id]
                
                tracked_objects.append(obj_with_tracking)
            
            # Create new trackers for unmatched detections
            for j in range(len(detected_objects)):
                if j not in matched_detections:
                    obj = detected_objects[j]
                    
                    tracker_id = self.next_id
                    self.next_id += 1
                    
                    # Initialize Kalman filter
                    self.kalman_filters[tracker_id] = self._initialize_kalman_filter()
                    kalman = self.kalman_filters[tracker_id]
                    
                    # Initialize state
                    state = np.array([
                        obj['center'][0], 
                        obj['center'][1], 
                        obj['width'],
                        obj['height'],
                        0, 0, 0, 0
                    ], np.float32)
                    kalman.statePost = state.reshape(8, 1)
                    
                    # Initialize tracking data
                    self.last_positions[tracker_id] = obj['center']
                    self.last_bboxes[tracker_id] = obj['bbox']
                    self.track_history[tracker_id] = [obj['center']]
                    self.class_history[tracker_id] = [obj['class_id']]
                    self.disappeared_count[tracker_id] = 0
                    
                    tracked_objects.append({
                        **obj,
                        'tracker_id': tracker_id,
                        'dominant_class': obj['class_id']
                    })
            
            # Remove trackers that have been missing for too long
            for tracker_id in list(self.disappeared_count.keys()):
                if self.disappeared_count[tracker_id] > self.max_disappeared:
                    if tracker_id in self.kalman_filters:
                        del self.kalman_filters[tracker_id]
                    if tracker_id in self.last_positions:
                        del self.last_positions[tracker_id]
                    if tracker_id in self.last_bboxes:
                        del self.last_bboxes[tracker_id]
                    if tracker_id in self.track_history:
                        del self.track_history[tracker_id]
                    if tracker_id in self.class_history:
                        del self.class_history[tracker_id]
                    del self.disappeared_count[tracker_id]
        
        return tracked_objects

def main():
    tracker = CombatZoneObjectTracker(model_path='/kaggle/working/runs/detect/train4/weights/best.pt', train_data='/kaggle/input/plzzz-bro/data.yaml', epochs=10)
    video_path = "/kaggle/input/suiiii/1090056871-preview.mp4"
    output_path = "/kaggle/working/combat_zone_tracking.avi"
    
    video_capture = cv2.VideoCapture(video_path)
    
    if not video_capture.isOpened():
        print(f"Error: Unable to open video file: {video_path}")
        return
    
    fourcc = cv2.VideoWriter_fourcc(*'XVID')
    fps = int(video_capture.get(cv2.CAP_PROP_FPS))
    width = int(video_capture.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(video_capture.get(cv2.CAP_PROP_FRAME_HEIGHT))
    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
    
    frame_count = 0
    
    while True:
        ret, frame = video_capture.read()
        if not ret:
            break
        
        frame_count += 1
        
        objects = tracker.detect_objects(frame)
        tracked_objects = tracker.track_objects(objects)
        
        # Draw tracking information for each object
        for obj in tracked_objects:
            x1, y1, x2, y2 = map(int, obj['bbox'])
            confidence = obj['confidence']
            tracker_id = obj['tracker_id']
            class_id = obj['dominant_class'] if 'dominant_class' in obj else obj['class_id']
            
            # Use consistent colors based on tracker_id
            color = ((tracker_id * 50) % 255, (tracker_id * 80) % 255, (tracker_id * 120) % 255)
            
            # Draw current bounding box with thicker lines
            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
            
            # Draw label with class name
            class_name = tracker.get_class_name(class_id)
            label = f"ID: {tracker_id} {class_name} {confidence:.2f}"
            
            # Improve text visibility with background
            label_size, baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)
            y_label = max(y1 - 10, label_size[1] + 10)
            cv2.rectangle(frame, (x1, y_label - label_size[1] - 10), (x1 + label_size[0], y_label + baseline - 10), (154, 148, 152), cv2.FILLED)
            cv2.putText(frame, label, (x1, y_label - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
            
            # Draw predicted future position (red box)
            if 'predicted_bbox' in obj:
                px1, py1, px2, py2 = map(int, obj['predicted_bbox'])
                # Ensure the predicted box stays within frame boundaries
                px1 = max(0, min(px1, width-1))
                py1 = max(0, min(py1, height-1))
                px2 = max(0, min(px2, width-1))
                py2 = max(0, min(py2, height-1))
                cv2.rectangle(frame, (px1, py1), (px2, py2), (0, 0, 255), 2)  # Red box for prediction
                
                # Draw an arrow from current position to predicted position
                current_center = ((x1 + x2) // 2, (y1 + y2) // 2)
                predicted_center = ((px1 + px2) // 2, (py1 + py2) // 2)
                cv2.arrowedLine(frame, current_center, predicted_center, (0, 0, 255), 2)
        
        # Add frame counter at the top left with better visibility
        cv2.rectangle(frame, (5, 5), (180, 40), (0, 0, 0), cv2.FILLED)
        cv2.putText(frame, f"Frame: {frame_count}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        
        # Write frame to output video
        out.write(frame)
    
    video_capture.release()
    out.release()
    print(f"Processing complete. Output saved as {output_path}")

if __name__ == "__main__":
    main()
