import cv2
import os
import numpy as np
import torch
from ultralytics import YOLO
from typing import List, Dict
from scipy.spatial.distance import cdist
import yaml

class CombatZoneObjectTracker:
    def _init_(self, model_path: str = 'best.pt', train_data: str = '/kaggle/input/plzzz-bro/data.yaml', epochs: int = 10):
        # Load class names from data.yaml
        self.class_names = self._load_class_names(train_data)
        print(f"Loaded {len(self.class_names)} class names: {self.class_names}")
        
        if not os.path.exists(model_path):
            print("Trained model not found. Starting training...")
            self._train_model(train_data, epochs)
        else:
            print(f"Loading trained model: {model_path}")
        self.detection_model = YOLO(model_path)
        print("YOLO model loaded successfully")
        
        # Tracking state
        self.kalman_filters = {}
        self.last_positions = {}
        self.last_bboxes = {}
        self.track_history = {}  # Store history of positions for each tracker
        self.class_history = {}  # Store history of class IDs for each tracker
        self.next_id = 0
        
        # Improved parameters
        self.disappeared_count = {}
        self.max_disappeared = 60  # Increased from 30 to 60 frames for more persistence
        self.distance_threshold = 150  # Increased from 100 to 150 for better matching
        
        # Additional parameters for better tracking
        self.iou_threshold = 0.3  # Threshold for IOU matching
        self.history_length = 20  # Number of frames to keep in history
        self.min_hits = 3  # Minimum detections before considering a track confirmed

    def _load_class_names(self, data_yaml_path: str) -> List[str]:
        """Load class names from YAML file"""
        try:
            with open(data_yaml_path, 'r') as file:
                data = yaml.safe_load(file)
                class_names = data.get('names', {})
                
                # Handle both list and dict formats
                if isinstance(class_names, list):
                    return class_names
                elif isinstance(class_names, dict):
                    # Sort by class index if it's a dictionary
                    max_idx = max(int(k) for k in class_names.keys() if k.isdigit())
                    sorted_names = ["Unknown"] * (max_idx + 1)
                    for k, v in class_names.items():
                        if k.isdigit():
                            sorted_names[int(k)] = v
                    return sorted_names
                else:
                    print("Warning: Unexpected class names format in data.yaml. Using default names.")
                    return [f"Class_{i}" for i in range(100)]
        except Exception as e:
            print(f"Error reading data.yaml: {e}. Using default names.")
            return [f"Class_{i}" for i in range(100)]

    def _train_model(self, data_path: str, epochs: int):
        model = YOLO("yolov8m.pt")  # Start with YOLOv8 Medium
        model.train(data=data_path, epochs=epochs)
        trained_model_path = "runs/train/exp/weights/best.pt"
        if os.path.exists(trained_model_path):
            print(f"Training complete. Using {trained_model_path}")
            self.detection_model = YOLO(trained_model_path)
        else:
            print("Error: Training failed, model not found.")

    def _initialize_kalman_filter(self):
        kalman = cv2.KalmanFilter(8, 4)  # 8-state: [x, y, w, h, vx, vy, vw, vh], 4-measurement: [x, y, w, h]
        
        # Set measurement matrix to relate state to measurement
        kalman.measurementMatrix = np.array([
            [1, 0, 0, 0, 0, 0, 0, 0],
            [0, 1, 0, 0, 0, 0, 0, 0],
            [0, 0, 1, 0, 0, 0, 0, 0],
            [0, 0, 0, 1, 0, 0, 0, 0]
        ], np.float32)
        
        # Set transition matrix for constant velocity model (includes box dimensions)
        kalman.transitionMatrix = np.array([
            [1, 0, 0, 0, 1, 0, 0, 0],  # x = x + vx
            [0, 1, 0, 0, 0, 1, 0, 0],  # y = y + vy
            [0, 0, 1, 0, 0, 0, 1, 0],  # w = w + vw
            [0, 0, 0, 1, 0, 0, 0, 1],  # h = h + vh
            [0, 0, 0, 0, 1, 0, 0, 0],  # vx = vx
            [0, 0, 0, 0, 0, 1, 0, 0],  # vy = vy
            [0, 0, 0, 0, 0, 0, 1, 0],  # vw = vw
            [0, 0, 0, 0, 0, 0, 0, 1]   # vh = vh
        ], np.float32)
        
        # Tune process noise for different state components
        kalman.processNoiseCov = np.diag([
            0.01,  # x position
            0.01,  # y position
            0.01,  # width
            0.01,  # height
            0.1,   # x velocity - higher noise
            0.1,   # y velocity - higher noise
            0.01,  # width change
            0.01   # height change
        ]).astype(np.float32)
        
        # Tune measurement noise
        kalman.measurementNoiseCov = np.diag([
            0.1,  # x position measurement
            0.1,  # y position measurement
            0.5,  # width measurement - higher noise
            0.5   # height measurement - higher noise
        ]).astype(np.float32)
        
        return kalman

    def _calculate_iou(self, box1, box2):
        """Calculate IoU between two bounding boxes [x1, y1, x2, y2]"""
        # Extract coordinates
        x1_1, y1_1, x2_1, y2_1 = box1
        x1_2, y1_2, x2_2, y2_2 = box2
        
        # Calculate area of each box
        area1 = (x2_1 - x1_1) * (y2_1 - y1_1)
        area2 = (x2_2 - x1_2) * (y2_2 - y1_2)
        
        # Calculate coordinates of intersection
        x1_i = max(x1_1, x1_2)
        y1_i = max(y1_1, y1_2)
        x2_i = min(x2_1, x2_2)
        y2_i = min(y2_1, y2_2)
        
        # Calculate intersection area
        if x2_i <= x1_i or y2_i <= y1_i:
            return 0.0  # No intersection
        
        intersection_area = (x2_i - x1_i) * (y2_i - y1_i)
        
        # Calculate union area
        union_area = area1 + area2 - intersection_area
        
        # Calculate IoU
        return intersection_area / union_area if union_area > 0 else 0.0
    
    def detect_objects(self, frame: np.ndarray) -> List[Dict]:
        results = self.detection_model(frame, conf=0.4)  # Slightly higher confidence threshold
        detected_objects = []
        
        for result in results:
            for box in result.boxes:
                x1, y1, x2, y2 = map(int, box.xyxy[0])
                confidence = float(box.conf[0])
                class_id = int(box.cls[0])
                
                # Get class name
                class_name = self._get_class_name(class_id)
                
                # Skip small detections as they're often false positives
                w, h = x2 - x1, y2 - y1
                if w < 20 or h < 20:
                    continue
                
                center_x = (x1 + x2) / 2
                center_y = (y1 + y2) / 2
                
                detected_objects.append({
                    'bbox': [x1, y1, x2, y2],
                    'width': w,
                    'height': h,
                    'confidence': confidence,
                    'center': (center_x, center_y),
                    'class_id': class_id,
                    'class_name': class_name
                })
        
        return detected_objects
    
    def _get_class_name(self, class_id):
        """Get class name from class ID with safety check"""
        if 0 <= class_id < len(self.class_names):
            return self.class_names[class_id]
        return f"Class_{class_id}"
    
    def _get_dominant_class(self, tracker_id):
        """Return the most common class ID for this tracker"""
        if tracker_id not in self.class_history or not self.class_history[tracker_id]:
            return None
        
        # Count occurrences of each class
        class_counts = {}
        for class_id in self.class_history[tracker_id]:
            if class_id not in class_counts:
                class_counts[class_id] = 0
            class_counts[class_id] += 1
        
        # Return the most common class
        return max(class_counts, key=class_counts.get)
    
    def track_objects(self, detected_objects: List[Dict]) -> List[Dict]:
        tracked_objects = []
        
        # Mark all existing trackers as disappeared for this frame
        for tracker_id in list(self.last_positions.keys()):
            if tracker_id not in self.disappeared_count:
                self.disappeared_count[tracker_id] = 0
            self.disappeared_count[tracker_id] += 1
        
        # If no objects detected, update disappeared counters and return empty list
        if len(detected_objects) == 0:
            # Remove trackers that have been missing for too long
            for tracker_id in list(self.disappeared_count.keys()):
                if self.disappeared_count[tracker_id] > self.max_disappeared:
                    if tracker_id in self.kalman_filters:
                        del self.kalman_filters[tracker_id]
                    if tracker_id in self.last_positions:
                        del self.last_positions[tracker_id]
                    if tracker_id in self.last_bboxes:
                        del self.last_bboxes[tracker_id]
                    if tracker_id in self.track_history:
                        del self.track_history[tracker_id]
                    if tracker_id in self.class_history:
                        del self.class_history[tracker_id]
                    del self.disappeared_count[tracker_id]
            return []
        
        # If we have no existing trackers, initialize all as new
        if len(self.last_positions) == 0:
            for obj in detected_objects:
                center = obj['center']
                bbox = obj['bbox']
                width = obj['width']
                height = obj['height']
                class_id = obj['class_id']
                
                tracker_id = self.next_id
                self.next_id += 1
                
                # Initialize Kalman filter
                self.kalman_filters[tracker_id] = self._initialize_kalman_filter()
                kalman = self.kalman_filters[tracker_id]
                
                # Initialize state
                state = np.array([center[0], center[1], width, height, 0, 0, 0, 0], np.float32)
                kalman.statePost = state.reshape(8, 1)
                
                # Initialize history tracking
                self.last_positions[tracker_id] = center
                self.last_bboxes[tracker_id] = bbox
                self.track_history[tracker_id] = [center]
                self.class_history[tracker_id] = [class_id]
                self.disappeared_count[tracker_id] = 0
                
                tracked_objects.append({
                    **obj,
                    'tracker_id': tracker_id,
                    'dominant_class': class_id,
                    'dominant_class_name': self._get_class_name(class_id)
                })
        else:
            # First prediction step for all existing Kalman filters
            predictions = {}
            for tracker_id, kalman in self.kalman_filters.items():
                prediction = kalman.predict()
                x, y, w, h = prediction[0:4]
                x, y, w, h = float(x), float(y), float(w), float(h)
                pred_bbox = [x - w/2, y - h/2, x + w/2, y + h/2]  # convert to [x1,y1,x2,y2]
                predictions[tracker_id] = {
                    'center': (x, y),
                    'bbox': pred_bbox,
                    'width': w,
                    'height': h
                }
            
            # Calculate IoU matrix between predictions and detections
            iou_matrix = np.zeros((len(self.last_positions), len(detected_objects)))
            for i, tracker_id in enumerate(self.last_positions.keys()):
                for j, obj in enumerate(detected_objects):
                    if tracker_id in predictions:
                        iou = self._calculate_iou(predictions[tracker_id]['bbox'], obj['bbox'])
                        iou_matrix[i, j] = iou
            
            # Calculate distance matrix for centers
            dist_matrix = np.zeros((len(self.last_positions), len(detected_objects)))
            tracker_ids = list(self.last_positions.keys())
            centers = [predictions[tid]['center'] for tid in tracker_ids]
            detection_centers = [obj['center'] for obj in detected_objects]
            
            if centers and detection_centers:
                dist_matrix = cdist(centers, detection_centers)
            
            # Combined matching using IoU and distance
            matched_indices = []
            
            # First, try matching with IoU
            for i, tracker_id in enumerate(tracker_ids):
                for j in range(len(detected_objects)):
                    if iou_matrix[i, j] > self.iou_threshold:
                        matched_indices.append((i, j))
                        break
            
            # For unmatched trackers and detections, try distance-based matching
            matched_trackers = {i for i, _ in matched_indices}
            matched_detections = {j for _, j in matched_indices}
            
            for i, tracker_id in enumerate(tracker_ids):
                if i in matched_trackers:
                    continue
                    
                # Get class history for this tracker
                dominant_class = self._get_dominant_class(tracker_id)
                
                for j in range(len(detected_objects)):
                    if j in matched_detections:
                        continue
                        
                    # Check if distance is within threshold
                    if dist_matrix[i, j] <= self.distance_threshold:
                        # Bonus: check if class matches dominant class (if available)
                        if dominant_class is not None and detected_objects[j]['class_id'] == dominant_class:
                            matched_indices.append((i, j))
                            matched_trackers.add(i)
                            matched_detections.add(j)
                            break
                
                # If still not matched by class, just use distance
                if i not in matched_trackers:
                    min_dist_idx = None
                    min_dist = float('inf')
                    for j in range(len(detected_objects)):
                        if j in matched_detections:
                            continue
                        if dist_matrix[i, j] < min_dist and dist_matrix[i, j] <= self.distance_threshold:
                            min_dist = dist_matrix[i, j]
                            min_dist_idx = j
                    
                    if min_dist_idx is not None:
                        matched_indices.append((i, min_dist_idx))
                        matched_trackers.add(i)
                        matched_detections.add(min_dist_idx)
            
            # Update matched trackers
            for i, j in matched_indices:
                tracker_id = tracker_ids[i]
                obj = detected_objects[j]
                
                # Update Kalman filter with new measurement
                kalman = self.kalman_filters[tracker_id]
                measurement = np.array([
                    obj['center'][0], 
                    obj['center'][1], 
                    obj['width'], 
                    obj['height']
                ], dtype=np.float32).reshape(4, 1)
                
                kalman.correct(measurement)
                
                # Update last known position and bbox
                self.last_positions[tracker_id] = obj['center']
                self.last_bboxes[tracker_id] = obj['bbox']
                
                # Update history
                self.track_history[tracker_id].append(obj['center'])
                if len(self.track_history[tracker_id]) > self.history_length:
                    self.track_history[tracker_id] = self.track_history[tracker_id][-self.history_length:]
                
                self.class_history[tracker_id].append(obj['class_id'])
                if len(self.class_history[tracker_id]) > self.history_length:
                    self.class_history[tracker_id] = self.class_history[tracker_id][-self.history_length:]
                
                # Reset disappeared counter
                self.disappeared_count[tracker_id] = 0
                
                # Add to tracked objects with dominant class
                dominant_class = self._get_dominant_class(tracker_id)
                dominant_class_name = self._get_class_name(dominant_class) if dominant_class is not None else "Unknown"
                
                tracked_objects.append({
                    **obj,
                    'tracker_id': tracker_id,
                    'dominant_class': dominant_class,
                    'dominant_class_name': dominant_class_name
                })
            
            # Create new trackers for unmatched detections
            for j in range(len(detected_objects)):
                if j not in matched_detections:
                    obj = detected_objects[j]
                    
                    tracker_id = self.next_id
                    self.next_id += 1
                    
                    # Initialize Kalman filter
                    self.kalman_filters[tracker_id] = self._initialize_kalman_filter()
                    kalman = self.kalman_filters[tracker_id]
                    
                    # Initialize state
                    state = np.array([
                        obj['center'][0], 
                        obj['center'][1], 
                        obj['width'],
                        obj['height'],
                        0, 0, 0, 0
                    ], np.float32)
                    kalman.statePost = state.reshape(8, 1)
                    
                    # Initialize tracking data
                    self.last_positions[tracker_id] = obj['center']
                    self.last_bboxes[tracker_id] = obj['bbox']
                    self.track_history[tracker_id] = [obj['center']]
                    self.class_history[tracker_id] = [obj['class_id']]
                    self.disappeared_count[tracker_id] = 0
                    
                    tracked_objects.append({
                        **obj,
                        'tracker_id': tracker_id,
                        'dominant_class': obj['class_id'],
                        'dominant_class_name': obj['class_name']
                    })
            
            # Remove trackers that have been missing for too long
            for tracker_id in list(self.disappeared_count.keys()):
                if self.disappeared_count[tracker_id] > self.max_disappeared:
                    if tracker_id in self.kalman_filters:
                        del self.kalman_filters[tracker_id]
                    if tracker_id in self.last_positions:
                        del self.last_positions[tracker_id]
                    if tracker_id in self.last_bboxes:
                        del self.last_bboxes[tracker_id]
                    if tracker_id in self.track_history:
                        del self.track_history[tracker_id]
                    if tracker_id in self.class_history:
                        del self.class_history[tracker_id]
                    del self.disappeared_count[tracker_id]
        
        return tracked_objects

def main():
    tracker = CombatZoneObjectTracker(model_path='/kaggle/working/runs/detect/train4/weights/best.pt', train_data='/kaggle/input/plzzz-bro/data.yaml', epochs=10)
    video_path = "/kaggle/input/suiiii/1090056871-preview.mp4"
    output_path = "/kaggle/working/combat_zone_tracking.avi"
    
    video_capture = cv2.VideoCapture(video_path)
    
    if not video_capture.isOpened():
        print(f"Error: Unable to open video file: {video_path}")
        return
    
    fourcc = cv2.VideoWriter_fourcc(*'XVID')
    fps = int(video_capture.get(cv2.CAP_PROP_FPS))
    width = int(video_capture.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(video_capture.get(cv2.CAP_PROP_FRAME_HEIGHT))
    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
    
    frame_count = 0
    
    while True:
        ret, frame = video_capture.read()
        if not ret:
            break
        
        frame_count += 1
        
        objects = tracker.detect_objects(frame)
        tracked_objects = tracker.track_objects(objects)
        
        # Draw tracking lines for each object
        for obj in tracked_objects:
            x1, y1, x2, y2 = map(int, obj['bbox'])
            confidence = obj['confidence']
            tracker_id = obj['tracker_id']
            class_name = obj['dominant_class_name'] if 'dominant_class_name' in obj else obj['class_name']
            
            # Use consistent colors based on tracker_id
            color = ((tracker_id * 50) % 255, (tracker_id * 80) % 255, (tracker_id * 120) % 255)
            
            # Draw bounding box
            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
            
            # Draw label with class name
            label = f"ID: {tracker_id} {class_name} {confidence:.2f}"
            
            # Calculate label background size
            (label_width, label_height), baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)
            
            # Draw label background
            cv2.rectangle(frame, 
                          (x1, y1 - label_height - 10), 
                          (x1 + label_width + 10, y1), 
                          color, 
                          -1)  # Filled rectangle
            
            # Draw white text for better visibility
            cv2.putText(frame, label, (x1 + 5, y1 - 7), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
            
            # Draw tracking line using history
            if tracker_id in tracker.track_history and len(tracker.track_history[tracker_id]) > 1:
                history = tracker.track_history[tracker_id]
                for i in range(1, len(history)):
                    p1 = tuple(map(int, history[i-1]))
                    p2 = tuple(map(int, history[i]))
                    thickness = 2
                    cv2.line(frame, p1, p2, color, thickness)
        
        # Add frame counter at the top left
        cv2.putText(frame, f"Frame: {frame_count}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        
        # Write frame to output video
        out.write(frame)
    
    video_capture.release()
    out.release()
    print(f"Processing complete. Output saved as {output_path}")

if _name_ == "_main_":
    main()